{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82uSVAMBc31t","executionInfo":{"status":"ok","timestamp":1697978930994,"user_tz":-120,"elapsed":25867,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}},"outputId":"4e0d0111-6420-47ba-a4ed-f83a68598077"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ASAL7fSoLIE5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!pip install ydata_profiling\n","!pip install pandas-profiling"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcx0BNsjtMWd","executionInfo":{"status":"ok","timestamp":1697978987826,"user_tz":-120,"elapsed":41721,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}},"outputId":"131e8b68-495a-4a76-c4fc-4ca53ffc5996"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pandas-profiling\n","  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ydata-profiling (from pandas-profiling)\n","  Downloading ydata_profiling-4.6.0-py2.py3-none-any.whl (357 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.5/357.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy<1.12,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.11.3)\n","Requirement already satisfied: pandas!=1.4.0,<2.1,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.5.3)\n","Requirement already satisfied: matplotlib<=3.7.3,>=3.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (3.7.1)\n","Requirement already satisfied: pydantic<2,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.10.13)\n","Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (6.0.1)\n","Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (3.1.2)\n","Collecting visions[type_image_path]==0.7.5 (from ydata-profiling->pandas-profiling)\n","  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<1.26,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.23.5)\n","Collecting htmlmin==0.1.12 (from ydata-profiling->pandas-profiling)\n","  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting phik<0.13,>=0.11.1 (from ydata-profiling->pandas-profiling)\n","  Downloading phik-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (2.31.0)\n","Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (4.66.1)\n","Requirement already satisfied: seaborn<0.13,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.12.2)\n","Collecting multimethod<2,>=1.4 (from ydata-profiling->pandas-profiling)\n","  Downloading multimethod-1.10-py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.14.0)\n","Collecting typeguard<5,>=4.1.2 (from ydata-profiling->pandas-profiling)\n","  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n","Collecting imagehash==4.3.1 (from ydata-profiling->pandas-profiling)\n","  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wordcloud>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.9.2)\n","Collecting dacite>=1.8 (from ydata-profiling->pandas-profiling)\n","  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba<0.59.0,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.56.4)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (9.4.0)\n","Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (23.1.0)\n","Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (3.1)\n","Collecting tangled-up-in-unicode>=0.0.4 (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling)\n","  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas-profiling) (2.1.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling->pandas-profiling) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling->pandas-profiling) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling->pandas-profiling) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling->pandas-profiling) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling->pandas-profiling) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling->pandas-profiling) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling->pandas-profiling) (2.8.2)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba<0.59.0,>=0.56.0->ydata-profiling->pandas-profiling) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba<0.59.0,>=0.56.0->ydata-profiling->pandas-profiling) (67.7.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<2.1,>1.1->ydata-profiling->pandas-profiling) (2023.3.post1)\n","Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas-profiling) (1.3.2)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.8.1->ydata-profiling->pandas-profiling) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2023.7.22)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling->pandas-profiling) (0.5.3)\n","Collecting typing-extensions>=4.2.0 (from pydantic<2,>=1.8.1->ydata-profiling->pandas-profiling)\n","  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling->pandas-profiling) (1.16.0)\n","Building wheels for collected packages: htmlmin\n","  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27081 sha256=fa66c10167e5635d89e2ede2905cd43ebdc1ba93623e081b50e13ef038121352\n","  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n","Successfully built htmlmin\n","Installing collected packages: htmlmin, typing-extensions, tangled-up-in-unicode, multimethod, dacite, typeguard, imagehash, visions, phik, ydata-profiling, pandas-profiling\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed dacite-1.8.1 htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.10 pandas-profiling-3.6.6 phik-0.12.3 tangled-up-in-unicode-0.2.0 typeguard-4.1.5 typing-extensions-4.8.0 visions-0.7.5 ydata-profiling-4.6.0\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"6-ELzRpbX8K-","executionInfo":{"status":"ok","timestamp":1697979040519,"user_tz":-120,"elapsed":4,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}}},"outputs":[],"source":["import duckdb\n","import glob\n","import time\n","import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.linear_model import LinearRegression\n","#import ydata_profiling\n","#from pandas_profiling import ProfileReport\n","#from ydata_profiling import ProfileReport\n","#import pandas_profiling\n","#from pandas_profiling import ProfileReport\n","#from pandas_profiling.utils.cache import cache_file\n","\n","pd.set_option('display.max_rows', None) # for printing full dataframe"]},{"cell_type":"code","source":["#Creating a connection to the duck db database:\n","conn = duckdb.connect()\n","\n","#Set working directory\n","os.chdir('/content/drive/MyDrive/Project ADSDB Max_Julian/landing/persistent')\n","\n","#Load 2 csv files and merge them\n","worldometer_complete = conn.execute(\"\"\"SELECT * FROM read_csv_auto(['worldometer_v1_2023-10-07 12:49:49.csv',\n","'worldometer_v2_2023-10-07 12:49:49.csv'], union_by_name=true)\"\"\").df()\n","\n"],"metadata":{"id":"kwmlz80jc5-X","executionInfo":{"status":"ok","timestamp":1697979046266,"user_tz":-120,"elapsed":2788,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["**Data Cleaning**"],"metadata":{"id":"U6erujHv4jec"}},{"cell_type":"code","source":["data = worldometer_complete\n","#Delete columns with many missing values (more than 30 %): \"NewCases\", 'NewDeaths', 'NewRecovered'\n","data = data.drop([\"NewCases\", 'NewDeaths', 'NewRecovered','Serious,Critical'], axis = 1)#, ])\n","\n","#After some EDA, we do this:\n","USA_pop_2022 = 338289857 / 1000000 # source: https://www.worldometers.info/world-population/us-population/\n","\n","#set None values to -1 so i can identify and change them\n","data['Tot Cases/1M pop'] = data['Tot Cases/1M pop'].fillna(-1)\n","data['Deaths/1M pop'] = data['Deaths/1M pop'].fillna(-1)\n","data['Tests/1M pop'] = data['Tests/1M pop'].fillna(-1)\n","\n","#expert imputing (for USA). The only missings are for a part of data for USA\n","data['Population'] = data['Population'].fillna(USA_pop_2022)\n","\n","for ind in data.index:\n","    if data['Tot Cases/1M pop'][ind] == -1 and data['Country,Other'][ind] == 'USA':\n","      data['Tot Cases/1M pop'][ind] = data['TotalCases'][ind] / USA_pop_2022\n","    if data['Deaths/1M pop'][ind] == -1 and data['Country,Other'][ind] == 'USA':\n","      data['Deaths/1M pop'][ind] = data['TotalDeaths'][ind] / USA_pop_2022\n","    if data['Tests/1M pop'][ind] == -1 and data['Country,Other'][ind] == 'USA':\n","      data['Tests/1M pop'][ind] = data['TotalTests'][ind] / USA_pop_2022\n","\n","for ind in data.index: #set values back to missing\n","    if data['Tot Cases/1M pop'][ind] == -1:\n","      data['Tot Cases/1M pop'][ind] = None\n","    if data['Deaths/1M pop'][ind] == -1:\n","      data['Deaths/1M pop'][ind] = None\n","    if data['Tests/1M pop'][ind] == -1:\n","      data['Tests/1M pop'][ind] = None\n","\n","#There is a negative value for 'ActiveCases' in Brunei at 2022-05-03, we replace it with the\n","#values from the day before in Brunei, because there are some mistakes, either in the\n","#'TotalCases','TotalDeaths', or 'TotalRecovered', because the value for 'ActiveCases'.\n","#data.loc[12373] = 'Brunei',141911.0 , 218.0, 141022.0, 671.0, 318790.0, 490.0, 717784.0, 1612436.0, 445155.0, '2022-05-03'\n","\n","data.loc[12373][4] = None"],"metadata":{"id":"abdYr90-kf6x","executionInfo":{"status":"ok","timestamp":1697979051192,"user_tz":-120,"elapsed":4066,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c128488e-bddc-4b1e-c1cb-702a6adf5caf"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-529ab4293995>:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Tot Cases/1M pop'][ind] = data['TotalCases'][ind] / USA_pop_2022\n","<ipython-input-9-529ab4293995>:20: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Deaths/1M pop'][ind] = data['TotalDeaths'][ind] / USA_pop_2022\n","<ipython-input-9-529ab4293995>:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Tests/1M pop'][ind] = data['TotalTests'][ind] / USA_pop_2022\n","<ipython-input-9-529ab4293995>:30: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Tests/1M pop'][ind] = None\n","<ipython-input-9-529ab4293995>:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Deaths/1M pop'][ind] = None\n","<ipython-input-9-529ab4293995>:37: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.loc[12373][4] = None\n"]}]},{"cell_type":"markdown","source":["**Data Imputation using interpolation**"],"metadata":{"id":"xwr7ALJal4vd"}},{"cell_type":"code","source":["pip install prophet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eB8U2HVJcx3V","executionInfo":{"status":"ok","timestamp":1697979237231,"user_tz":-120,"elapsed":6330,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}},"outputId":"ca32e77f-31ec-4830-bad8-66913d4761db"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: prophet in /usr/local/lib/python3.10/dist-packages (1.1.5)\n","Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from prophet) (1.2.0)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from prophet) (1.23.5)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from prophet) (3.7.1)\n","Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from prophet) (1.5.3)\n","Requirement already satisfied: holidays>=0.25 in /usr/local/lib/python3.10/dist-packages (from prophet) (0.35)\n","Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.10/dist-packages (from prophet) (4.66.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from prophet) (6.1.0)\n","Requirement already satisfied: stanio~=0.3.0 in /usr/local/lib/python3.10/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.3.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from holidays>=0.25->prophet) (2.8.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (3.1.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.4->prophet) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->holidays>=0.25->prophet) (1.16.0)\n"]}]},{"cell_type":"code","source":["N = 200\n","df = data\n","grouped = df.groupby('Country,Other')\n","# Function to check if a group has more than a specified number of missing values for 'TotalDeaths'\n","def has_more_than_N_missing(group, N):\n","    return group['TotalDeaths'].isna().sum() > N\n","\n","# Group by 'Country,Other'\n","grouped = data.groupby('Country,Other')\n","\n","# Filter out countries with more than N missing values in 'TotalDeaths'\n","filtered_group = grouped.filter(lambda x: not has_more_than_N_missing(x, N))\n","\n","# Reset the index of the resulting DataFrame\n","filtered_group = filtered_group.reset_index(drop=True)\n","\n","# Print the filtered DataFrame\n","names = []\n","grouped = filtered_group.groupby('Country,Other')\n","for i in range(1,9):\n","  for name,g in grouped:\n","    if g.iloc[:,i].isna().sum() > 140:\n","      #names.append(g.iloc[0,0])\n","      #print(g.iloc[0,0], i)\n","      if g.iloc[0,0] not in names:\n","        names.append(g.iloc[0,0])\n","# names2 = []\n","# for name, group in grouped:\n","#     # Check if there are more than 140 missing values in any column for the group\n","#     if group\n","#     if group.drop('Country,Other', axis=1).isna().sum().max() > 140:\n","#         names2.append(name)\n","print(len(names), names)\n","#print(len(names2), names2)\n","\n","\n","new_data = df\n","names.append('Falkland Islands')\n","names.append('Saint Helena')\n","names.append('Tuvalu')\n","names.append('Vatican City')\n","names.append('DPRK')\n","names.append('Tajikistan')\n","names.append('Western Sahara')\n","\n","\n","for i in names:\n","  new_data = new_data.loc[new_data['Country,Other'] != i ] #not in names]\n","#print(new_data.isna().sum())\n","#Niue has too many missings in total death"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-kvSxfprVZw9","executionInfo":{"status":"ok","timestamp":1697984506781,"user_tz":-120,"elapsed":1030,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}},"outputId":"62ef68fa-f67d-4dec-c655-24fa557b4f2b"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["16 ['Niue', 'British Virgin Islands', 'Faeroe Islands', 'French Polynesia', 'Iceland', 'Laos', 'Sierra Leone', 'St. Barth', 'Sudan', 'Tanzania', 'Tunisia', 'Comoros', 'Kiribati', 'Marshall Islands', 'Nicaragua', 'Seychelles']\n"]}]},{"cell_type":"code","source":["ind = data.loc[data['Country,Other'] == 'Falkland Islands']\n","print(ind.iloc[:,2].isna().sum())\n","ind.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HP3zS1iKbyBy","executionInfo":{"status":"ok","timestamp":1697986835897,"user_tz":-120,"elapsed":345,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}},"outputId":"445d8a97-f158-4693-8db4-11b94732337e"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["201\n"]},{"output_type":"execute_result","data":{"text/plain":["Country,Other         0\n","TotalCases            0\n","TotalDeaths         201\n","TotalRecovered      180\n","ActiveCases         180\n","Tot Cases/1M pop      0\n","Deaths/1M pop       201\n","TotalTests            0\n","Tests/1M pop          0\n","Population            0\n","Date                  0\n","dtype: int64"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["#Filter after ChatGPT solves it 19.36\n","# Filter the countries that have more than N missings in 1 or more columns\n","N = 200\n","df = data\n","grouped = df.groupby('Country,Other')\n","unique_country_names = set()\n","\n","# Function to check if a group has more than a specified number of missing values for a given column\n","def has_more_than_N_missing(group, column, N):\n","    return group[column].isna().sum() > N\n","count = 0\n","names = []\n","columns = ['TotalCases', 'TotalDeaths', 'TotalRecovered', 'ActiveCases',\n","                   'Tot Cases/1M pop', 'Deaths/1M pop', 'TotalTests', 'Tests/1M pop']\n","for i in range(8):\n","  for name, group in grouped:\n","    if has_more_than_N_missing(group, columns[i], 100):\n","      names.append(name)\n","      #print(name)\n","      count+=1\n","print('count = ', count)\n","new_data = data\n","for i in names:\n","  new_data = new_data.loc[new_data['Country,Other'] != i ] #not in names]\n","#print(data.isna().sum(), new_data.isna().sum())\n","\n","df = new_data\n","\n","grouped = df.groupby('Country,Other')\n","\n","# Initialize an empty list to store the imputed DataFrames\n","imputed_dataframes = []\n","\n","# Iterate through each group and impute missing values for all columns except 'Date'\n","for name, group in grouped:\n","    group.loc[:, group.columns != 'Date'] = group.loc[:, group.columns != 'Date'].interpolate()\n","    imputed_dataframes.append(group)\n","\n","# Concatenate the imputed DataFrames back into one final DataFrame\n","imputed_df = pd.concat(imputed_dataframes, ignore_index=True)\n","print(imputed_df.isna().sum(), new_data.isna().sum())\n","\n","\n","import numpy as np\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.linear_model import LinearRegression\n","\n","lr = LinearRegression()\n","imp = IterativeImputer(estimator=lr,missing_values=np.nan, max_iter=10, verbose=2, imputation_order='roman',random_state=0)\n","\n","#numerical_columns = imputed_df.select_dtypes(include=['number'])\n","\n","grouped_for_mice = imputed_df.groupby('Country,Other')\n","\n","# Initialize an empty list to store the imputed DataFrames\n","imputed_dataframes = []\n","\n","# Iterate through each group and impute missing values for all columns except 'Date'\n","for name, group in grouped_for_mice:\n","    num_group = group.select_dtypes(include=['number'])\n","    num_group = imp.fit_transform(num_group)\n","    num_group\n","    imputed_dataframes.append(group)\n","#X=imp.fit_transform(X)\n","imputed_df2 = pd.concat(imputed_dataframes, ignore_index=True)\n","print(imputed_df.isna().sum(), imputed_df2.isna().sum())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807},"id":"lsjPgm-RTqwR","executionInfo":{"status":"error","timestamp":1697988731052,"user_tz":-120,"elapsed":2202,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}},"outputId":"adea228f-c851-47f1-9ebb-16a91535ce3a"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["count =  52\n","Country,Other         0\n","TotalCases            0\n","TotalDeaths         338\n","TotalRecovered      117\n","ActiveCases          93\n","Tot Cases/1M pop      0\n","Deaths/1M pop       338\n","TotalTests          300\n","Tests/1M pop        300\n","Population            0\n","Date                  0\n","dtype: int64 Country,Other          0\n","TotalCases             0\n","TotalDeaths          338\n","TotalRecovered      1113\n","ActiveCases         1089\n","Tot Cases/1M pop       0\n","Deaths/1M pop        338\n","TotalTests           300\n","Tests/1M pop         300\n","Population             0\n","Date                   0\n","dtype: int64\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-f8536b99077b>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mnumerical_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputed_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mgrouped_for_mice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Country,Other'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Initialize an empty list to store the imputed DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   8400\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8402\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   8403\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8404\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    966\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    886\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Country,Other'"]}]},{"cell_type":"code","source":["#Filter the countries that have more than N missings in 1 or more columns\n","N = 200\n","df = data\n","grouped = df.groupby('Country,Other')\n","names = []\n","def has_more_than_10_missing(group,number):\n","    return group.iloc[:,number].isna().sum() > N\n","\n","for name,group in grouped:\n","  for i in range(1,9):\n","    if has_more_than_10_missing(group,i):\n","      if group.iat[0,0] not in names:\n","        names.append(group.iat[0,0])\n","\n","# Function to check if a group has more than a specified number of missing values for a given column\n","def has_more_than_N_missing(group, column, N):\n","    return group[column].isna().sum() > N\n","\n","# Specify the maximum number of missing values allowed for each column\n","max_missing_values = ['TotalCases', 'TotalDeaths', 'TotalRecovered', 'ActiveCases',\n","                   'Tot Cases/1M pop', 'Deaths/1M pop', 'TotalTests', 'Tests/1M pop']\n","\n","filtered_group = {}\n","\n","# Iterate through columns\n","for column in max_missing_values:\n","    filtered_group[column] = grouped.filter(lambda x: not has_more_than_N_missing(x, column, N))\n","\n","combined_df = pd.concat(filtered_group.values())\n","\n","# Reset the index of the combined DataFrame\n","combined_df = combined_df.reset_index(drop=True)\n","\n","# filtered_group will now be a dictionary where each key is a column name, and the value is the filtered group for that column\n","print(len(names), names)\n","print(data.isna().sum(), combined_df.isna().sum())"],"metadata":{"id":"UK9QrW_cHkpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#try 2 for prophet\n","import pandas as pd\n","from prophet import Prophet\n","import numpy as np\n","\n","# Create a sample DataFrame with missing values\n","df = new_data\n","\n","grouped = df.groupby('Country,Other')\n","\n","# Initialize an empty list to store the imputed DataFrames\n","imputed_dataframes = []\n","\n","# Iterate through each group and impute missing values for all columns except 'Date'\n","for name, group in grouped:\n","    group.loc[:, group.columns != 'Date'] = group.loc[:, group.columns != 'Date'].interpolate()\n","    imputed_dataframes.append(group)\n","\n","# Concatenate the imputed DataFrames back into one final DataFrame\n","imputed_df = pd.concat(imputed_dataframes, ignore_index=True)\n","\n","df = imputed_df\n","\n","# Convert the 'Date' column to a DatetimeIndex\n","df['Date'] = pd.to_datetime(df['Date'])\n","\n","# Group the DataFrame by the 'Country' column\n","grouped = df.groupby('Country,Other')\n","\n","# Initialize an empty list to store the imputed DataFrames\n","imputed_dataframes = []\n","\n","columns = ['TotalCases', 'TotalDeaths', 'TotalRecovered', 'ActiveCases',\n","                   'Tot Cases/1M pop', 'Deaths/1M pop', 'TotalTests', 'Tests/1M pop']\n","# Iterate through each group and impute missing values using Prophet\n","for column_name in columns:\n","  for name, group in grouped:\n","      print('column', column_name, ' of country', group.iloc[0,0], 'we are doing now:')\n","      # Create a Prophet model\n","      model = Prophet()\n","\n","      # Rename columns to fit Prophet's requirements\n","      group = group.rename(columns={'Date': 'ds', column_name : 'y'})\n","\n","      # Remove rows with missing values as Prophet can't handle them\n","      group = group.dropna(subset=['y'])\n","\n","      # Fit the model\n","      model.fit(group)\n","\n","      # Create a new DataFrame with future dates to impute missing values\n","      future = model.make_future_dataframe(periods=len(group), freq='D')\n","\n","      # Predict values for the future dates\n","      forecast = model.predict(future)\n","\n","      # Merge the original group data with the forecasted values\n","      imputed_group = group.merge(forecast[['ds', 'yhat']], on='ds', how='left')\n","\n","      # Rename columns back to their original names\n","      imputed_group = imputed_group.rename(columns={'ds': 'Date', 'yhat': column_name})\n","\n","      # Fill any remaining missing values with NaN\n","      imputed_group[column_name] = imputed_group[column_name].fillna(np.nan)\n","\n","      imputed_dataframes.append(imputed_group)\n","\n","\n","# Concatenate the imputed DataFrames back into one final DataFrame\n","imputed_df = pd.concat(imputed_dataframes, ignore_index=True)\n","\n","# Display the imputed DataFrame\n","print(data.isna().sum())\n","print(imputed_df.isna().sum())\n","\n"],"metadata":{"id":"0qGKw9osPEIN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# result:\n","Country,Other          0\n","TotalCases             0\n","TotalDeaths          781\n","TotalRecovered      3805\n","ActiveCases         3780\n","Tot Cases/1M pop       0\n","Deaths/1M pop        781\n","TotalTests          2155\n","Tests/1M pop        2155\n","Population             0\n","Date                   0\n","dtype: int64\n","Country,Other          0\n","y                      0\n","TotalDeaths         1264\n","TotalRecovered      9120\n","ActiveCases         9120\n","Tot Cases/1M pop       0\n","Deaths/1M pop       1264\n","TotalTests           352\n","Tests/1M pop         352\n","Population             0\n","Date                   0\n","TotalCases             0\n","dtype: int64"],"metadata":{"id":"0N5pEMwv1-Sc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#data['Date'] = pd.to_datetime(data['Date'])\n","\n","# Group the DataFrame by the 'Country' column\n","print(combined_df.isna().sum())\n","\n","grouped = combined_df.groupby('Country,Other')\n","\n","\n","# Initialize an empty list to store the imputed DataFrames\n","imputed_dataframes = []\n","\n","# Define numeric columns for interpolation\n","numeric_columns = ['TotalCases', 'TotalDeaths', 'TotalRecovered', 'ActiveCases',\n","                   'Tot Cases/1M pop', 'Deaths/1M pop', 'TotalTests', 'Tests/1M pop', 'Population']\n","\n","# Iterate through each group and impute missing values for numeric columns\n","for name, group in grouped:\n","    for column in numeric_columns:\n","        # Forward fill, then backward fill missing values\n","        #group[column] = group[column].fillna(method='ffill').fillna(method='bfill')\n","        group[column] = group[column].ffill().bfill()\n","        # Interpolate the remaining gaps\n","        group[column] = group[column].interpolate()\n","    imputed_dataframes.append(group)\n","\n","\n","# Concatenate the imputed DataFrames back into one final DataFrame\n","imputed_df = pd.concat(imputed_dataframes, ignore_index=True)\n","\n","# Sort the final DataFrame by 'Date'\n","#imputed_df = imputed_df.sort_values(by='Date')\n","\n","# Display the imputed DataFrame\n","#print(imputed_df)\n","print(imputed_df.isna().sum())\n","print(data.isna().sum())\n","#Set columns to correct type\n","#data = imputed_df.astype({'TotalRecovered': 'int32','ActiveCases': 'int32',\n","               # 'Tot Cases/1M pop': 'int32','Deaths/1M pop': 'int32','TotalTests': 'int32','Tests/1M pop': 'int32', })\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cs0iw5hZmm5G","executionInfo":{"status":"ok","timestamp":1697907450858,"user_tz":-120,"elapsed":2225,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}},"outputId":"daac9851-722f-493e-d6b7-6975dd8a619b"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Country,Other           0\n","TotalCases              0\n","TotalDeaths          4238\n","TotalRecovered      21852\n","ActiveCases         21656\n","Tot Cases/1M pop        0\n","Deaths/1M pop        4238\n","TotalTests          11758\n","Tests/1M pop        11758\n","Population              0\n","Date                    0\n","dtype: int64\n","Country,Other           0\n","TotalCases              0\n","TotalDeaths          2216\n","TotalRecovered       6276\n","ActiveCases          6084\n","Tot Cases/1M pop        0\n","Deaths/1M pop        2216\n","TotalTests          11132\n","Tests/1M pop        11132\n","Population              0\n","Date                    0\n","dtype: int64\n","Country,Other          0\n","TotalCases             0\n","TotalDeaths          781\n","TotalRecovered      3805\n","ActiveCases         3780\n","Tot Cases/1M pop       0\n","Deaths/1M pop        781\n","TotalTests          2155\n","Tests/1M pop        2155\n","Population             0\n","Date                   0\n","dtype: int64\n"]}]},{"cell_type":"markdown","source":["**Check if imputed values are reasonable**"],"metadata":{"id":"t7UImrfrqmzZ"}},{"cell_type":"code","source":["original_data = worldometer_complete\n","original_report = ProfileReport(original_data, title='Original Data')\n","#original_report.to_file(\"original_report.html\")\n","transformed_report = ProfileReport(data, title=\"Transformed Data\")\n","comparison_report = original_report.compare(transformed_report)\n","#comparison_report.to_file(\"original_vs_transformed.html\")"],"metadata":{"id":"Etw7aodzsXlT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["comparison_report"],"metadata":{"id":"5PLCgaYkr8zl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a sample DataFrame with missing values\n","# data = {\n","#     'Country': ['A', 'B', 'A', 'B', 'C', 'A', 'C'],\n","#     'TotalCases': [100, None, 200, 300, 400, None, 600],\n","#     'TotalDeaths': [10, 20, 30, None, 40, 50, None],\n","#     'TotalRecovered': [80, 70, None, 90, 60, None, 100],\n","#     'ActiveCases': [10, None, 20, 10, 10, None, 20],\n","#     'Tot Cases/1M pop': [1000, None, 2000, 3000, 4000, None, 5000],\n","#     'Deaths/1M pop': [100, None, 200, 300, 400, None, 500],\n","#     'TotalTests': [5000, 6000, 7000, 8000, 9000, 10000, 11000],\n","#     'Tests/1M pop': [50000, 60000, 70000, 80000, 90000, 100000, 110000],\n","#     'Population': [1000000, 2000000, 3000000, 4000000, 5000000, 6000000, 7000000],\n","#     'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-07']\n","# }\n","\n","#df = pd.DataFrame(data)\n","df = data\n","# Group the DataFrame by the 'Country' column\n","grouped = df.groupby('Country,Other')\n","\n","# Initialize an empty list to store the imputed DataFrames\n","imputed_dataframes = []\n","\n","# Iterate through each group and impute missing values for all columns except 'Date'\n","for name, group in grouped:\n","    group.loc[:, group.columns != 'Date'] = group.loc[:, group.columns != 'Date'].interpolate()\n","    imputed_dataframes.append(group)\n","\n","# Concatenate the imputed DataFrames back into one final DataFrame\n","imputed_df = pd.concat(imputed_dataframes, ignore_index=True)\n","\n","# Sort the final DataFrame by 'Date'\n","#imputed_df = imputed_df.sort_values(by='Date')\n","\n","# Display the imputed DataFrame\n","#print(imputed_df)"],"metadata":{"id":"jrB4N3JR6cHS","executionInfo":{"status":"ok","timestamp":1697836558774,"user_tz":-120,"elapsed":1659,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["**Export Preprocessed data to csv-file**"],"metadata":{"id":"XhCKwx-ypvFK"}},{"cell_type":"code","source":["data.to_csv('/content/drive/MyDrive/Project ADSDB Max_Julian/landing/persistent/worldometer_preprocessed_2023-10-20 16:24:36.csv')  # or True?"],"metadata":{"id":"qkO3P1izY-Pq","executionInfo":{"status":"ok","timestamp":1697811908933,"user_tz":-120,"elapsed":1059,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["#ActiveCases cant be negative\n","#ind = X.loc[X[3] < 1]\n","#print(ind)\n","#print(X[3][12373])\n","\n","#data_Brunei = data.loc[data[\"Country,Other\"] == 'Brunei']\n","#ind4 = ind_full.loc[ind_full['Date'] == '2022-05-04']\n","#ind3 = ind_full.loc[ind_full['Date'] == '2022-05-03']\n","#data_previous_day = data_Brunei.loc[data_Brunei['Date'] == '2022-05-02']# and data[\"Country,Other\"] == 'Brunei']\n","\n","ind = data.loc[data['Date'] == '2022-03-08']\n","print(ind)\n","#print(ind['ActiveCases'])\n","#for i in ind.index:\n","  #if ind['ActiveCases'][i] < 0:\n","    #print('bingo')\n","  #print(ind['ActiveCases'][i])\n","#ind['ActiveCases']\n","# for i in data.index:\n","#   if data['ActiveCases'][i] < 0:\n","#     print('bingo')\n","# data.loc[12373] = 'Brunei',141911.0 , 218.0, 141022.0, 671.0, 318790.0, 490.0, 717784.0, 1612436.0, 445155.0, '2022-05-03'\n","# for i in data.index:\n","#   if data['ActiveCases'][i] < 0:\n","#     print('bingo')\n","# print('no bingo')\n"],"metadata":{"id":"SLIitp4qrYcz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["profile = ProfileReport(data, title=\"Worldometer Dataset\")#, html={'style': {'full_width': True}}, sort=None)\n","profile"],"metadata":{"id":"wKPbR1XXqVnQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Notes\n","\n","#Delete row with a lot of missing values:\n","#nan_rows = data.isna()\n","#print(len(nan_rows))\n","#-----------------------------\n","#after imputing missing values, make sure all types are correct (int instead of float):\n","#df = df.astype({'TotalRecovered': 'int32','ActiveCases': 'int32','Serious/Critical': 'int32',\n","#'Tot Cases/1M pop': 'int32','Deaths/1M pop': 'int32','TotalTests': 'int32','Tests/1M pop': 'int32', })\n","#possible to overwrite error, but NaN gets replaced with <NA>'s:\n","#df = df.astype({'Serious/Critical': 'Int64'}, errors='ignore')\n","#---------------------------------\n","\n","df = data\n","indices = data.loc[databool[\"TotalDeaths\"]==True]\n","totdeath = data.loc[data['ActiveCases'] + data['TotalRecovered'] - data['TotalCases'] == 0]\n","print(totdeath)\n","df[\"TotalDeaths\"] = np.where(data['ActiveCases'] + data['TotalRecovered'] - data['TotalCases'] == 0, 0, np.nan)\n","#df = indices\n","\n","\n","#df = df.astype({'TotalRecovered': 'int32','ActiveCases': 'int32','Serious/Critical': 'int32',\n","                #'Tot Cases/1M pop': 'int32','Deaths/1M pop': 'int32','TotalTests': 'int32','Tests/1M pop': 'int32', })\n","#df = df.astype({'Serious/Critical': 'Int64'}, errors='ignore')\n","#-------------------------------------\n","databool = df.isna()\n","indices = data.loc[databool[\"TotalDeaths\"]==True]\n","totdeath = data.loc[data['ActiveCases'] + data['TotalRecovered'] - data['TotalCases'] == 0]\n","#print(totdeath)\n","data[\"TotalDeaths\"] = np.where(data['ActiveCases'] + data['TotalRecovered'] - data['TotalCases'] == 0, 0, np.nan)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDC3VX8T4wAj","executionInfo":{"status":"ok","timestamp":1697466640077,"user_tz":-120,"elapsed":333,"user":{"displayName":"Julian Fransen","userId":"10268924118413895126"}},"outputId":"44e846f9-6e71-4a61-c462-5e998bf35ea2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Empty DataFrame\n","Columns: [Country,Other, TotalCases, TotalDeaths, TotalRecovered, ActiveCases, Tot Cases/1M pop, Deaths/1M pop, TotalTests, Tests/1M pop, Population, Date]\n","Index: []\n"]}]}]}