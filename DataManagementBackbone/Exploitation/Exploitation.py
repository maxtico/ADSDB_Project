import glob
import time
import os
import pandas as pd
import numpy as np
import duckdb

def Exploitation(filepath,filedest):
    conn = duckdb.connect(database= os.path.join(filedest,"exploitation2.duckdb"),read_only=False)
    # Display our tables in duckdb
    file_list = os.listdir(filepath)
    # Initialize datafram   es to store the data
    for file in file_list:
        if file.endswith(".csv"):
            # Check if the file name contains "owid" or "worldometer"
            if "owid_preprocessed" in file:
                owid = pd.read_csv(filepath+file)
                owid_p=filepath+file
            elif "Worldometer_preprocessed" in file:
                worldometer = pd.read_csv(filepath+file)
                world_p=filepath+file
            elif "GDP" in file:
                gdp_raw = pd.read_csv(filepath+file, sep = ';')
                gpd_p = filepath+file

    # Cleaning
    owid.drop(['Unnamed: 0'],axis=1,inplace=True)
    worldometer.drop(['Unnamed: 0'],axis=1,inplace=True)    

    print(owid)
    gdp = gdp_raw.iloc[:,[0,1]]
    gdp = gdp.rename(columns={"Gross domestic product in 2020": "GDP","County": "Country"})
    gdp.replace("Hong Kong SAR China",
            "Hong Kong",
            inplace=True)
    gdp.replace("Macao SAR China",
            "Macao",
            inplace=True)
    gdp.replace("Turkiye",
            "Turkey",
            inplace=True)
    gdp.replace("Kyrgyz Republic",
            "Kyrgyzstan",
            inplace=True)

    # Merging dataframes
    merged = pd.merge(worldometer,owid,left_on = ['Country,Other','Date'], right_on =['location','date'])
    merged_df = pd.merge(merged,gdp,left_on = ['Country,Other'], right_on =['Country'])

    #Check if merging was correct:
    ind1 = merged_df.loc[merged_df['Date'] != merged_df['date']] #Matches everywhere
    ind2 = merged_df.loc[merged_df['Country,Other'] != merged_df['location']] #Matches everywhere

    #Remove redundant columns
    merged_df = merged_df.drop(['date','column00', 'location','Country'], axis=1)

    #We deal with the fact that we have two columns describring the population of a country, and the values do not exactly match in every instance.
    grouped = merged_df.groupby('Country,Other')

    diff = []
    for name, group in grouped:
        x = (np.mean(group['Population']) - np.mean(group['population'])) / (np.mean(group['Population']) + np.mean(group['population']) )
    if x > 0.05:
        diff.append([name, x])
    print(diff)
    #This shows that there is only one country where the difference in population data is bigger than 5%, thus we conclude that taking the average is a valid method.

    # Dealing with two populations
    average = ((merged_df['Population'] + merged_df['population']) / 2).round() #.astype(int)
    merged_df['Population'] = average
    merged_df = merged_df.drop(['population'], axis=1)
    merged_df = merged_df.rename(columns={"Country,Other": "Country"})

    # Saving them into a Database
    fnames = [world_p, owid_p]
    tnames = ['Worldometer', 'Owid']
    ds = ['worldometer', 'owid']
    for i in range(len(fnames)):
        conn.execute(f'DROP TABLE IF EXISTS {tnames[i]}')
        conn.execute(f"CREATE TABLE IF NOT EXISTS {tnames[i]} AS SELECT * FROM read_csv_auto('{fnames[i]}',header=True);")

    conn.execute(f'DROP TABLE IF EXISTS Merged')
    conn.execute("CREATE TABLE IF NOT EXISTS Merged AS SELECT * FROM merged_df;")
    #Close the connection
    conn.close()

    con = duckdb.connect(database= os.path.join(filedest, 'exploitation2.duckdb'), read_only=False)
    table_configs = [
        {
            'columns': "Date, 'Country', Population, Continent, GDP",
            'table_name': 'Country_info'
        },
        {
            'columns': "Date, 'Country', Population, human_development_index, life_expectancy, male_smokers, female_smokers, median_age",
            'table_name': 'Population_Health'
        },
        {
            'columns': "Date, 'Country', Population, new_vaccinations, total_vaccinations, people_vaccinated, TotalCases, TotalDeaths, TotalRecovered, ActiveCases",
            'table_name': 'Pandemic'
        }
    ]

    # Iterate through the list of dictionaries and create tables
    for config in table_configs:
        columns_to_select = config['columns']
        table_name = config['table_name']
        # Create the SQL query
        query = f"CREATE TABLE {table_name} AS SELECT {columns_to_select} FROM Merged"
        # Drop the table if it already exists
        con.execute(f'DROP TABLE IF EXISTS {table_name}')
        # Execute the SQL query to create the new table
        con.execute(query)

    con.close()

'''
rel_path = os.path.dirname(os.path.abspath(__name__))
destination_folder = rel_path+"/DataManagementBackbone/Landing/Persistent/"
exp_folder = rel_path+"/DataManagementBackbone/Exploitation/"

Exploitation(destination_folder,exp_folder)
'''